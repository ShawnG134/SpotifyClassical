{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25d5e824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "def generate_fictional_piece_names(num_pieces=100000):\n",
    "    genres = [\"Concerto\", \"Symphony\", \"Sonata\", \"Suite\", \"Overture\", \"Opera\", \"Quartet\", \"Trio\", \"Cantata\", \"Etude\", \"Prelude\", \"Rhapsody\", \"Serenade\", \"Nocturne\"]\n",
    "    instruments = [\"Piano\", \"Violin\", \"Cello\", \"Flute\", \"Clarinet\", \"Harp\", \"Guitar\", \"Oboe\", \"Bassoon\", \"Horn\", \"Trumpet\", \"Trombone\"]\n",
    "    keys = [\"C Major\", \"G Major\", \"D Major\", \"A Major\", \"E Major\", \"B Major\", \"F Major\", \"B-Flat Major\", \"E-Flat Major\", \"A-Flat Major\", \"D-Flat Major\", \"G-Flat Major\", \n",
    "            \"C Minor\", \"G Minor\", \"D Minor\", \"A Minor\", \"E Minor\", \"B Minor\", \"F Minor\", \"B-Flat Minor\", \"E-Flat Minor\", \"A-Flat Minor\", \"D-Flat Minor\", \"G-Flat Minor\"]\n",
    "    opus_numbers = [f\"Op. {i}\" for i in range(1, 201)]\n",
    "    k_numbers = [f\"K. {i}\" for i in range(1, 501)]\n",
    "    \n",
    "    piece_names = []\n",
    "    \n",
    "    for _ in range(num_pieces):\n",
    "        genre = random.choice(genres)\n",
    "        instrument = random.choice(instruments)\n",
    "        number = random.randint(1, 30)\n",
    "        key = random.choice(keys)\n",
    "        opus = random.choice(opus_numbers)\n",
    "        k_number = random.choice(k_numbers)\n",
    "        \n",
    "        piece_name = f\"{instrument} {genre} No. {number} in {key}, {opus}, {k_number}\"\n",
    "        piece_names.append(piece_name)\n",
    "    \n",
    "    return piece_names\n",
    "\n",
    "def generate_variations(piece_name):\n",
    "    parts = piece_name.split(\", \")\n",
    "    title = parts[0]\n",
    "    details = parts[1:] if len(parts) > 1 else []\n",
    "    \n",
    "    variations = set()\n",
    "    variations.add(piece_name)  # Original full name\n",
    "\n",
    "    if len(details) == 2:\n",
    "        # Drop either opus or K number, not both\n",
    "        variations.add(f\"{title}, {details[1]}\")  # Drop opus number\n",
    "        variations.add(f\"{title}, {details[0]}\")  # Drop K number\n",
    "        variations.add(f\"{title} ({details[0]})\")  # Title with opus number in brackets\n",
    "        variations.add(f\"{details[0]}, {title}\")  # Opus number first, then title\n",
    "        variations.add(f\"{details[1]}, {title}\")  # K number first, then title\n",
    "        variations.add(f\"{title}\")  # Only title\n",
    "    elif len(details) == 1:\n",
    "        variations.add(f\"{details[0]}, {title}\")  # Reorder\n",
    "        variations.add(f\"{title}\")  # Only title\n",
    "        variations.add(f\"{details[0]}\")  # Only details part\n",
    "\n",
    "    return list(variations)\n",
    "\n",
    "def generate_csv(piece_names, filename=\"classical_pieces.csv\"):\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Piece Name 1\", \"Piece Name 2\"])\n",
    "        count = 0\n",
    "        while count < 200000:\n",
    "            piece_name = random.choice(piece_names)\n",
    "            variations = generate_variations(piece_name)\n",
    "            if len(variations) > 1:\n",
    "                piece_pair = random.sample(variations, 2)\n",
    "                # Ensure neither of the names is just an opus or K number alone\n",
    "                if not (piece_pair[0].startswith(\"Op.\") or piece_pair[0].startswith(\"K.\")) and not (piece_pair[1].startswith(\"Op.\") or piece_pair[1].startswith(\"K.\")):\n",
    "                    writer.writerow(piece_pair)\n",
    "                    count += 1\n",
    "\n",
    "piece_names = generate_fictional_piece_names()\n",
    "generate_csv(piece_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6880f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "def generate_fictional_piece_names(num_pieces=100000):\n",
    "    genres = [\"Concerto\", \"Symphony\", \"Sonata\", \"Suite\", \"Overture\", \"Opera\", \"Quartet\", \"Trio\", \"Cantata\", \"Etude\", \"Prelude\", \"Rhapsody\", \"Serenade\", \"Nocturne\"]\n",
    "    instruments = [\"Piano\", \"Violin\", \"Cello\", \"Flute\", \"Clarinet\", \"Harp\", \"Guitar\", \"Oboe\", \"Bassoon\", \"Horn\", \"Trumpet\", \"Trombone\"]\n",
    "    keys = [\"C Major\", \"G Major\", \"D Major\", \"A Major\", \"E Major\", \"B Major\", \"F Major\", \"B-Flat Major\", \"E-Flat Major\", \"A-Flat Major\", \"D-Flat Major\", \"G-Flat Major\", \n",
    "            \"C Minor\", \"G Minor\", \"D Minor\", \"A Minor\", \"E Minor\", \"B Minor\", \"F Minor\", \"B-Flat Minor\", \"E-Flat Minor\", \"A-Flat Minor\", \"D-Flat Minor\", \"G-Flat Minor\"]\n",
    "    opus_numbers = [f\"Op. {i}\" for i in range(1, 201)]\n",
    "    k_numbers = [f\"K. {i}\" for i in range(1, 501)]\n",
    "    \n",
    "    piece_names = []\n",
    "    \n",
    "    for _ in range(num_pieces):\n",
    "        genre = random.choice(genres)\n",
    "        instrument = random.choice(instruments)\n",
    "        number = random.randint(1, 30)\n",
    "        key = random.choice(keys)\n",
    "        opus = random.choice(opus_numbers)\n",
    "        k_number = random.choice(k_numbers)\n",
    "        \n",
    "        piece_name = f\"{instrument} {genre} No. {number} in {key}, {opus}, {k_number}\"\n",
    "        piece_names.append(piece_name)\n",
    "    \n",
    "    return piece_names\n",
    "\n",
    "def generate_similar_but_different_pairs(piece_names, num_pairs=200000):\n",
    "    keys = [\"C Major\", \"G Major\", \"D Major\", \"A Major\", \"E Major\", \"B Major\", \"F Major\", \"B-Flat Major\", \"E-Flat Major\", \"A-Flat Major\", \"D-Flat Major\", \"G-Flat Major\", \n",
    "            \"C Minor\", \"G Minor\", \"D Minor\", \"A Minor\", \"E Minor\", \"B Minor\", \"F Minor\", \"B-Flat Minor\", \"E-Flat Minor\", \"A-Flat Minor\", \"D-Flat Minor\", \"G-Flat Minor\"]\n",
    "    opus_numbers = [f\"Op. {i}\" for i in range(1, 201)]\n",
    "    k_numbers = [f\"K. {i}\" for i in range(1, 501)]\n",
    "    \n",
    "    pairs = []\n",
    "    for _ in range(num_pairs):\n",
    "        piece_name = random.choice(piece_names)\n",
    "        \n",
    "        # Split the piece name into components\n",
    "        parts = piece_name.split(\", \")\n",
    "        title_parts = parts[0].split(\" \")\n",
    "        \n",
    "        # Ensure changing the number after the genre\n",
    "        number_index = title_parts.index(\"No.\") + 1  # Index of the number after \"No.\"\n",
    "        new_number = random.randint(1, 30)\n",
    "        while new_number == int(title_parts[number_index]):\n",
    "            new_number = random.randint(1, 30)\n",
    "        title_parts[number_index] = str(new_number)\n",
    "\n",
    "        # Optionally, make additional changes to ensure diversity\n",
    "        change_attribute = random.choice([\"key\", \"opus\", \"k_number\"])\n",
    "        \n",
    "        if change_attribute == \"key\":\n",
    "            key_index = title_parts.index(\"in\") + 1  # Index of the key after \"in\"\n",
    "            new_key = random.choice(keys)\n",
    "            while new_key == \" \".join(title_parts[key_index:key_index + 2]):\n",
    "                new_key = random.choice(keys)\n",
    "            title_parts[key_index:key_index + 2] = new_key.split()\n",
    "        \n",
    "        elif change_attribute == \"opus\":\n",
    "            new_opus = random.choice(opus_numbers)\n",
    "            while new_opus == parts[1]:\n",
    "                new_opus = random.choice(opus_numbers)\n",
    "            parts[1] = new_opus\n",
    "        \n",
    "        elif change_attribute == \"k_number\":\n",
    "            new_k_number = random.choice(k_numbers)\n",
    "            while new_k_number == parts[2]:\n",
    "                new_k_number = random.choice(k_numbers)\n",
    "            parts[2] = new_k_number\n",
    "        \n",
    "        # Reconstruct the similar but different piece name\n",
    "        similar_piece_name = \" \".join(title_parts)\n",
    "        similar_piece_full_name = f\"{similar_piece_name}, {parts[1]}, {parts[2]}\"\n",
    "        \n",
    "        pairs.append((piece_name, similar_piece_full_name))\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "def generate_csv(pairs, filename=\"different_classical_pieces.csv\"):\n",
    "    with open(filename, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Piece Name 1\", \"Piece Name 2\"])\n",
    "        writer.writerows(pairs)\n",
    "\n",
    "# Generate the piece names\n",
    "piece_names = generate_fictional_piece_names()\n",
    "\n",
    "# Generate the pairs of similar but different pieces\n",
    "pairs = generate_similar_but_different_pairs(piece_names)\n",
    "\n",
    "# Save to CSV\n",
    "generate_csv(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "343d63d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV files\n",
    "csv1 = pd.read_csv('classical_pieces.csv')\n",
    "csv2 = pd.read_csv('different_classical_pieces.csv')\n",
    "\n",
    "# Append a new column with value 1 to the first CSV\n",
    "csv1['new_column'] = 1\n",
    "\n",
    "# Append a new column with value 0 to the second CSV\n",
    "csv2['new_column'] = 0\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "merged_csv = pd.concat([csv1, csv2], ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_csv.to_csv('path_to_merged_csv.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1780673",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99f66875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:  14%|█▉            | 11238/80001 [06:41<40:55, 28.01it/s, loss=44.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed. Loss: 44.4298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10:  14%|█▌         | 11238/80001 [06:39<40:46, 28.11it/s, loss=4.27e-8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed. Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10:  14%|█▊           | 11238/80001 [07:01<42:57, 26.68it/s, loss=0.914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed. Loss: 0.9142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10:  14%|█▊           | 11238/80001 [06:40<40:51, 28.05it/s, loss=0.317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed. Loss: 0.3175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10:  14%|█▍        | 11238/80001 [07:05<43:21, 26.43it/s, loss=3.45e-12]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed. Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10:  14%|█▍        | 11238/80001 [06:59<42:47, 26.78it/s, loss=1.24e-15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 completed. Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10:  14%|█▍        | 11238/80001 [07:07<43:36, 26.28it/s, loss=4.96e-18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed. Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10:  14%|█▍        | 11238/80001 [07:46<47:32, 24.11it/s, loss=2.81e-16]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 completed. Loss: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10:  14%|█▊           | 11238/80001 [08:25<51:30, 22.25it/s, loss=0.357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 completed. Loss: 0.3570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10:  14%|█▌         | 11238/80001 [08:05<49:30, 23.15it/s, loss=0.0013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 completed. Loss: 0.0013\n",
      "\n",
      "Evaluating the model on the validation set...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Different       1.00      1.00      1.00     40000\n",
      "        Same       1.00      1.00      1.00     40000\n",
      "\n",
      "    accuracy                           1.00     80000\n",
      "   macro avg       1.00      1.00      1.00     80000\n",
      "weighted avg       1.00      1.00      1.00     80000\n",
      "\n",
      "Model saved to classical_piece_classifier\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.training import Example\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "df['combined_text'] = df['Piece Name 1'] + \" ||| \" + df['Piece Name 2']\n",
    "\n",
    "train_df, valid_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df['new_column']\n",
    ")\n",
    "\n",
    "def create_training_data(dataframe):\n",
    "    training_data = []\n",
    "    for _, row in dataframe.iterrows():\n",
    "        text = row['combined_text']\n",
    "        label = 'SAME' if row['new_column'] == 1 else 'DIFFERENT'\n",
    "        cats = {'SAME': label == 'SAME', 'DIFFERENT': label == 'DIFFERENT'}\n",
    "        training_data.append((text, cats))\n",
    "    return training_data\n",
    "\n",
    "train_data = create_training_data(train_df)\n",
    "valid_data = create_training_data(valid_df)\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "if \"textcat\" not in nlp.pipe_names:\n",
    "    textcat = nlp.add_pipe(\"textcat\", last=True)\n",
    "else:\n",
    "    textcat = nlp.get_pipe(\"textcat\")\n",
    "\n",
    "textcat.add_label(\"SAME\")\n",
    "textcat.add_label(\"DIFFERENT\")\n",
    "\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"textcat\"]\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    optimizer = nlp.begin_training()\n",
    "    n_iter = 10\n",
    "\n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(n_iter):\n",
    "        random.shuffle(train_data)\n",
    "        losses = {}\n",
    "        batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001))\n",
    "        progress = tqdm(batches, total=max(1, len(train_data) // 4 + 1), desc=f\"Epoch {epoch+1}/{n_iter}\")\n",
    "        for batch in progress:\n",
    "            texts, annotations = zip(*batch)\n",
    "            examples = []\n",
    "            for text, cats in zip(texts, annotations):\n",
    "                doc = nlp.make_doc(text)\n",
    "                example = Example.from_dict(doc, {\"cats\": cats})\n",
    "                examples.append(example)\n",
    "            nlp.update(\n",
    "                examples,\n",
    "                sgd=optimizer,\n",
    "                drop=0.2,\n",
    "                losses=losses\n",
    "            )\n",
    "            progress.set_postfix(loss=losses.get('textcat', 0.0))\n",
    "        print(f\"Epoch {epoch +1} completed. Loss: {losses['textcat']:.4f}\")\n",
    "\n",
    "print(\"\\nEvaluating the model on the validation set...\")\n",
    "\n",
    "valid_texts = [text for text, _ in valid_data]\n",
    "true_labels = [1 if cats['SAME'] else 0 for _, cats in valid_data]\n",
    "\n",
    "docs = list(nlp.pipe(valid_texts))\n",
    "pred_labels = []\n",
    "for doc in docs:\n",
    "    if doc.cats['SAME'] > doc.cats['DIFFERENT']:\n",
    "        pred_labels.append(1)\n",
    "    else:\n",
    "        pred_labels.append(0)\n",
    "\n",
    "report = classification_report(true_labels, pred_labels, target_names=['Different', 'Same'])\n",
    "print(report)\n",
    "\n",
    "model_path = \"classical_piece_classifier\"\n",
    "\n",
    "nlp.to_disk(model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "def predict_same_piece(piece1, piece2, nlp_model):\n",
    "    combined_text = piece1 + \" ||| \" + piece2\n",
    "    doc = nlp_model(combined_text)\n",
    "    return 1 if doc.cats['SAME'] > doc.cats['DIFFERENT'] else 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
